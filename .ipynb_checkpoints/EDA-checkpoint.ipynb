{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b68fdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf12f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data in various formats, including CSV, Excel, and SQL databases.\n",
    "def user():\n",
    "    def process_csv(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "\n",
    "    def process_excel(file_path):\n",
    "        df = pd.read_excel(file_path)\n",
    "        return df\n",
    "\n",
    "    def process_sql(database_path):\n",
    "        # Create your connection.\n",
    "        conn = sqlite3.connect(database_path, table_name)\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        return df\n",
    "    \n",
    "    try:\n",
    "        print(\"Please, Enter the path of the file\")\n",
    "        print(\"Make sure the file extension is 'csv', 'xlsx' or 'db'\")\n",
    "        file_path = input()\n",
    "        if file_path.split('.')[1] == 'csv':\n",
    "            return process_csv(file_path)\n",
    "        elif file_path.split('.')[1] == 'xlsx':\n",
    "            return process_excel(file_path)\n",
    "        elif file_path.split('.')[1] == 'db':\n",
    "            table_name = input(\"Please, Enter the table name: \")\n",
    "            return process_sql(database_path, table_name)\n",
    "    except:\n",
    "        print(\"Opps, you input something error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c538f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying the data types of each column\n",
    "def identifying_column(df):\n",
    "    print(\"\\n\")\n",
    "    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(\"Dataframe:\")\n",
    "    print(\"\\n\")\n",
    "    print(df)\n",
    "    print(\"\\n\")\n",
    "    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(\"identifying the data types of each column:\")\n",
    "    print(\"\\n\")\n",
    "    print(pd.DataFrame(df.dtypes))\n",
    "    print(\"\\n\")\n",
    "    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(\"identifying the data types of each column:\")\n",
    "    print(\"\\n\")\n",
    "    print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293052ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling duplicates and nulls values\n",
    "def handle_duplicates_and_nulls(df):\n",
    "    # print(df.duplicated())\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"\\n\")\n",
    "    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(\"\\n\")\n",
    "    print(\"The duplicated rows had handled\")\n",
    "    print(\"\\n\")\n",
    "    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(\"Sum of null values:\")\n",
    "    print(\"\\n\")\n",
    "    print(df.isna().sum())\n",
    "    print(\"\\n\")\n",
    "    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print(\"\\n\")\n",
    "    lst_of_columns_name = list (df.columns)\n",
    "    lst_of_types = list(dict(pd.DataFrame(df.dtypes))[0])\n",
    "    lst_of_null_values =  list(df.isna().sum())\n",
    "    for i in range(0, len(lst_of_null_values)):\n",
    "        if lst_of_null_values[i] != 0:\n",
    "            print(f\"A column named '{lst_of_columns_name[i]}' and type '{lst_of_types[i]}' contains ({lst_of_null_values[i]}) null values\")\n",
    "            if lst_of_types[i] != \"object\":\n",
    "                print(\"Please, Enter the number of your choice to handle missing data\")\n",
    "                print(\"1) Dropping rows with missing values\")\n",
    "                print(\"2) Imputing missing values with the median\")\n",
    "                print(\"3) Imputing missing values with the mean\")\n",
    "                print(\"4) Imputing missing values a constant\")\n",
    "                print(\"5) None\")\n",
    "                answer = input()\n",
    "                if answer == \"1\":\n",
    "                    # Handling missing data (dropping rows with missing values)\n",
    "                    df = df.dropna()\n",
    "                elif answer == \"2\": \n",
    "                    # Handling missing data (imputing missing values with the median)\n",
    "                    df = df.fillna(df.median())\n",
    "                elif answer == \"3\":\n",
    "                    # Handling missing data (imputing missing values with the mean)\n",
    "                    df = df.fillna(df.mean())\n",
    "                elif answer == \"4\":\n",
    "                    # Handling missing data (imputing missing values with a constant)\n",
    "                    constant = input('Please, Enter the constant ')\n",
    "                    df = df.fillna(constant)\n",
    "                elif answer == \"5\":\n",
    "                    print(\"Ok\")\n",
    "                    print(\"The nulls values had not handled\")\n",
    "                else:\n",
    "                    print(f\"You made the wrong choice --> {answer}\")\n",
    "                    print(\"The nulls values had handled by dropping rows with missing values\")\n",
    "                    df = df.dropna()\n",
    "            else:\n",
    "                print(\"Please, Enter the number of your choice to handle missing data\")\n",
    "                print(\"1) Dropping rows with missing values\")\n",
    "                print(\"2) Imputing missing values a constant\")\n",
    "                print(\"3) None\")\n",
    "                answer = input()\n",
    "                if answer == \"1\":\n",
    "                    # Handling missing data (dropping rows with missing values)\n",
    "                    df = df.dropna()\n",
    "                elif answer == \"2\":\n",
    "                    # Handling missing data (imputing missing values with a constant)\n",
    "                    constant = input('Please, Enter the constant ')\n",
    "                    df = df.fillna(constant)\n",
    "                elif answer == \"3\":\n",
    "                    print(\"Ok\")\n",
    "                    print(\"The nulls values had not handled\")\n",
    "                else:\n",
    "                    print(f\"You made the wrong choice --> {answer}\")\n",
    "                    print(\"The nulls values had handled by dropping rows with missing values\")\n",
    "                    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb94ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncoding categorical features\n",
    "def encode_categorical_features(df):\n",
    "    # turn df into dict\n",
    "    df_dict = df.to_dict(orient='records') \n",
    "    # instantiate a Dictvectorizer object for X\n",
    "    dv_X = DictVectorizer(sparse=False)  # sparse = False makes the output is not a sparse matrix\n",
    "    # apply dv_X on df_dict\n",
    "    X_encoded = dv_X.fit_transform(df_dict)\n",
    "    return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62deef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical features\n",
    "def normalize_dataframe(df):\n",
    "    lst_of_columns_name = list (df.columns)\n",
    "    lst_of_types = list(dict(pd.DataFrame(df.dtypes))[0])\n",
    "    for index in range(0, len(lst_of_types)):\n",
    "        if lst_of_types[index] == \"object\":\n",
    "            df = df.drop(lst_of_columns_name[index], axis=1)\n",
    "    \n",
    "    # Pandas Normalize using Mean Normalization\n",
    "    normalized_df=df.apply(lambda x: (x-x.mean())/ x.std(), axis=0)\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01dafcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visualization(df):\n",
    "    def Plot_details(columns):\n",
    "        plt.figure(figsize=(10,7))\n",
    "        plt.plot(df[columns], df[columns] , label = columns)\n",
    "        # add label in x-axis and y-axis\n",
    "        plt.xlabel(columns)\n",
    "        plt.ylabel(columns)\n",
    "        # add title for graph\n",
    "        plt.title(f'plot for {columns}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "    def Bar_chart(columns):\n",
    "        count = df[columns].value_counts()\n",
    "        count = pd.DataFrame(count)\n",
    "        plt.bar(count.T.columns, count[columns], label = columns)\n",
    "        plt.xlabel(columns)\n",
    "        plt.title(f'Bar chart for {columns}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    def histogram(columns):\n",
    "        plt.figure(figsize=(10,7))\n",
    "        plt.hist(df[columns], bins= 100, color='red', label = columns)\n",
    "        # add label in x-axis and y-axis\n",
    "        plt.xlabel(columns)\n",
    "        # add title for graph\n",
    "        plt.title(f'plot for {columns}')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def Scatter_plot(columns_1, columns_2):\n",
    "        plt.scatter(df[columns_1], df[columns_2], color='red', label= f'{columns_1} vs {columns_2}')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def Pie_chart(columns):\n",
    "        count = df[columns].value_counts()\n",
    "        print(count)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.pie(count, labels=count.index.values.tolist(), rotatelabels=True)\n",
    "        plt.title(columns)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    lst_of_columns_name = list (df.columns)\n",
    "    lst_of_types = list(dict(pd.DataFrame(df.dtypes))[0])\n",
    "    \n",
    "    for index in range(0, len(lst_of_types)):\n",
    "        if lst_of_types[index] != \"object\":\n",
    "            print(f'Any graphical relations you want to apply to {lst_of_columns_name[index]}?')\n",
    "            print(\"Please, Enter the numbers of your choices separated by ','\")\n",
    "            print(\"1) Plot Details\")\n",
    "            print(\"2) Bar Chart\")\n",
    "            print(\"3) Histogram\")\n",
    "            print(\"4) Pie Chart\")\n",
    "            print(\"5) None\")\n",
    "            answer = input()\n",
    "            answer = answer.split(',')\n",
    "            for i in answer:\n",
    "                if i == \"1\":\n",
    "                    Plot_details(lst_of_columns_name[index])\n",
    "                elif i == \"2\": \n",
    "                    Bar_chart(lst_of_columns_name[index])\n",
    "                elif i == \"3\":\n",
    "                    histogram(lst_of_columns_name[index])\n",
    "                elif i == \"4\":\n",
    "                    Pie_chart(lst_of_columns_name[index])\n",
    "                elif i == \"5\":\n",
    "                    print(\"Ok\") \n",
    "                else:\n",
    "                    print(f\"You made the wrong choice --> {i}\")\n",
    "    \n",
    "        else:\n",
    "            print(f'Any graphical relations you want to apply to {lst_of_columns_name[index]}?')\n",
    "            print(\"Please, Enter the numbers of your choices separated by ','\")\n",
    "            print(\"1) Bar Chart\")\n",
    "            print(\"2) Pie Chart\")\n",
    "            print(\"3) None\")\n",
    "            answer = input()\n",
    "            answer = answer.split(',')\n",
    "            for i in answer:\n",
    "                if i == \"1\":\n",
    "                    Bar_chart(lst_of_columns_name[index])\n",
    "                elif i == \"2\": \n",
    "                    Pie_chart(lst_of_columns_name[index])\n",
    "                elif i == \"3\":\n",
    "                    print(\"Ok\")\n",
    "                else:\n",
    "                    print(f\"You made the wrong choice --> {i}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94b0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, Enter the path of the file\n",
      "Make sure the file extension is 'csv', 'xlsx' or 'db'\n",
      "International_Report_Passengers.csv\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Dataframe:\n",
      "\n",
      "\n",
      "      data_dte  Year  Month  usg_apt_id usg_apt  usg_wac  fg_apt_id fg_apt  \\\n",
      "0   05/01/2014  2014      5       14492     RDU       36      11032    CUN   \n",
      "1   06/01/2007  2007      6       13204     MCO       33      16085    YHZ   \n",
      "2   12/01/2005  2005     12       11433     DTW       43      10411    AUA   \n",
      "3   04/01/2003  2003      4       13487     MSP       63      16304    ZIH   \n",
      "4   12/01/2005  2005     12       12016     GUM        5      11138    CRK   \n",
      "..         ...   ...    ...         ...     ...      ...        ...    ...   \n",
      "95  02/01/2008  2008      2       13303     MIA       33      10911    CCS   \n",
      "96  06/01/2003  2003      6       11433     DTW       43      13180    MBJ   \n",
      "97  06/01/2004  2004      6       10529     BDL       11      11032    CUN   \n",
      "98  08/01/2008  2008      8       11433     DTW       43      16271    YYZ   \n",
      "99  07/01/2004  2004      7       14057     PDX       92      16257    YYC   \n",
      "\n",
      "    fg_wac  airlineid carrier  carriergroup        type  Scheduled  Charter  \\\n",
      "0      148      19534      AM             0  Passengers          0      315   \n",
      "1      951      20364      C6             0  Passengers          0      683   \n",
      "2      277      20344      RD             1  Passengers          0     1010   \n",
      "3      148      20204      MG             1  Passengers          0      508   \n",
      "4      766      20312      TZ             1  Passengers          0       76   \n",
      "..     ...        ...     ...           ...         ...        ...      ...   \n",
      "95     388      20203     FCQ             1  Passengers          0     3542   \n",
      "96     243      20147      T9             1  Passengers          0      683   \n",
      "97     148      20423      U5             1  Passengers          0      639   \n",
      "98     936      20402      GL             1  Passengers          0       44   \n",
      "99     916      20203     FCQ             1  Passengers          0       29   \n",
      "\n",
      "    Total  \n",
      "0     315  \n",
      "1     683  \n",
      "2    1010  \n",
      "3     508  \n",
      "4      76  \n",
      "..    ...  \n",
      "95   3542  \n",
      "96    683  \n",
      "97    639  \n",
      "98     44  \n",
      "99     29  \n",
      "\n",
      "[100 rows x 16 columns]\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "identifying the data types of each column:\n",
      "\n",
      "\n",
      "                   0\n",
      "data_dte      object\n",
      "Year           int64\n",
      "Month          int64\n",
      "usg_apt_id     int64\n",
      "usg_apt       object\n",
      "usg_wac        int64\n",
      "fg_apt_id      int64\n",
      "fg_apt        object\n",
      "fg_wac         int64\n",
      "airlineid      int64\n",
      "carrier       object\n",
      "carriergroup   int64\n",
      "type          object\n",
      "Scheduled      int64\n",
      "Charter        int64\n",
      "Total          int64\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "identifying the data types of each column:\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   data_dte      100 non-null    object\n",
      " 1   Year          100 non-null    int64 \n",
      " 2   Month         100 non-null    int64 \n",
      " 3   usg_apt_id    100 non-null    int64 \n",
      " 4   usg_apt       100 non-null    object\n",
      " 5   usg_wac       100 non-null    int64 \n",
      " 6   fg_apt_id     100 non-null    int64 \n",
      " 7   fg_apt        100 non-null    object\n",
      " 8   fg_wac        100 non-null    int64 \n",
      " 9   airlineid     100 non-null    int64 \n",
      " 10  carrier       98 non-null     object\n",
      " 11  carriergroup  100 non-null    int64 \n",
      " 12  type          100 non-null    object\n",
      " 13  Scheduled     100 non-null    int64 \n",
      " 14  Charter       100 non-null    int64 \n",
      " 15  Total         100 non-null    int64 \n",
      "dtypes: int64(11), object(5)\n",
      "memory usage: 12.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "\n",
      "The duplicated rows had handled\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "\n",
      "data_dte        0\n",
      "Year            0\n",
      "Month           0\n",
      "usg_apt_id      0\n",
      "usg_apt         0\n",
      "usg_wac         0\n",
      "fg_apt_id       0\n",
      "fg_apt          0\n",
      "fg_wac          0\n",
      "airlineid       0\n",
      "carrier         2\n",
      "carriergroup    0\n",
      "type            0\n",
      "Scheduled       0\n",
      "Charter         0\n",
      "Total           0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "\n",
      "A column named 'carrier' and type 'object' contains (2) null values\n",
      "Please, Enter the number of your choice to handle missing data\n",
      "1) Dropping rows with missing values\n",
      "2) Imputing missing values a constant\n",
      "3) None\n",
      "1\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Encodedf\n",
      "\n",
      "\n",
      "[[3.1500e+02 5.0000e+00 0.0000e+00 ... 0.0000e+00 1.4492e+04 3.6000e+01]\n",
      " [6.8300e+02 6.0000e+00 0.0000e+00 ... 0.0000e+00 1.3204e+04 3.3000e+01]\n",
      " [1.0100e+03 1.2000e+01 0.0000e+00 ... 0.0000e+00 1.1433e+04 4.3000e+01]\n",
      " ...\n",
      " [6.3900e+02 6.0000e+00 0.0000e+00 ... 0.0000e+00 1.0529e+04 1.1000e+01]\n",
      " [4.4000e+01 8.0000e+00 0.0000e+00 ... 0.0000e+00 1.1433e+04 4.3000e+01]\n",
      " [2.9000e+01 7.0000e+00 0.0000e+00 ... 0.0000e+00 1.4057e+04 9.2000e+01]]\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Normalized df\n",
      "\n",
      "\n",
      "        Year     Month  usg_apt_id   usg_wac  fg_apt_id    fg_wac  airlineid  \\\n",
      "0   3.141128 -0.314426    1.110188 -0.311267  -1.310408 -0.913272  -2.280957   \n",
      "1   0.689690 -0.031731    0.273881 -0.419822   1.143359  1.534250   0.421400   \n",
      "2  -0.010721  1.664440   -0.876040 -0.057970  -1.611969 -0.520084   0.356283   \n",
      "3  -0.711131 -0.597122    0.457635  0.665734   1.249707 -0.913272  -0.099536   \n",
      "4  -0.010721  1.664440   -0.497494 -1.433008  -1.258934  0.970375   0.252096   \n",
      "..       ...       ...         ...       ...        ...       ...        ...   \n",
      "95  1.039896 -1.162512    0.338163 -0.419822  -1.369166 -0.181759  -0.102792   \n",
      "96 -0.711131 -0.031731   -0.876040 -0.057970  -0.267326 -0.623715  -0.285120   \n",
      "97 -0.360926 -0.031731   -1.463013 -1.215897  -1.310408 -0.913272   0.613496   \n",
      "98  1.039896  0.533659   -0.876040 -0.057970   1.233682  1.488530   0.545123   \n",
      "99 -0.360926  0.250964    0.827740  1.715105   1.226884  1.427571  -0.102792   \n",
      "\n",
      "    carriergroup  Scheduled   Charter     Total  \n",
      "0      -1.573051        NaN -0.338595 -0.338595  \n",
      "1      -1.573051        NaN -0.010119 -0.010119  \n",
      "2       0.629220        NaN  0.281761  0.281761  \n",
      "3       0.629220        NaN -0.166324 -0.166324  \n",
      "4       0.629220        NaN -0.551926 -0.551926  \n",
      "..           ...        ...       ...       ...  \n",
      "95      0.629220        NaN  2.541820  2.541820  \n",
      "96      0.629220        NaN -0.010119 -0.010119  \n",
      "97      0.629220        NaN -0.049393 -0.049393  \n",
      "98      0.629220        NaN -0.580490 -0.580490  \n",
      "99      0.629220        NaN -0.593879 -0.593879  \n",
      "\n",
      "[98 rows x 11 columns]\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "\n",
      "Any graphical relations you want to apply to data_dte?\n",
      "Please, Enter the numbers of your choices separated by ','\n",
      "1) Bar Chart\n",
      "2) Pie Chart\n",
      "3) None\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "while flag:\n",
    "    try:\n",
    "        df = user()\n",
    "        #df = df.head(100)\n",
    "        identifying_column(df)\n",
    "        df = handle_duplicates_and_nulls(df)\n",
    "        encode_df = encode_categorical_features(df)\n",
    "        print(\"\\n\")\n",
    "        print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        print(\"Encode df\")\n",
    "        print(\"\\n\")\n",
    "        print(encode_df)\n",
    "        print(\"\\n\")\n",
    "        print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        normalized_df = normalize_dataframe(df)\n",
    "        print(\"Normalized df\")\n",
    "        print(\"\\n\")\n",
    "        print(normalized_df)\n",
    "        print(\"\\n\")\n",
    "        print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        print(\"\\n\")\n",
    "        data_visualization(df)\n",
    "        flag = False\n",
    "    except:\n",
    "        print('Do you want to enter the path of the file again?')\n",
    "        print(\"Please, Enter the number of your choice\")\n",
    "        print(\"Please note that if you enter a wrong choice, it will be charged 'no'.\")\n",
    "        print(\"1) YES\")\n",
    "        print(\"2) NO\")\n",
    "        answer = input()\n",
    "        if answer != \"1\":\n",
    "            flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b6fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
